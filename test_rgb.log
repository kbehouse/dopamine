in fetch_cam __init__
Choosing the latest nvidia driver: /usr/lib/nvidia-396, among ['/usr/lib/nvidia-375', '/usr/lib/nvidia-396']
Choosing the latest nvidia driver: /usr/lib/nvidia-396, among ['/usr/lib/nvidia-375', '/usr/lib/nvidia-396']
in continuous trani and eval
--------in RainbowRGBAgent------
in ORI rainbow _build_replay_buffer
self._observation_shape=(84, 84, 3), len(self._observation_shape)=3
storage_element =  shape_type(name='observation', shape=(84, 84, 3), type=<class 'numpy.uint8'>)
array_shape =  [100000, 84, 84, 3]
storage_element.name =  observation
storage_element.type =  <class 'numpy.uint8'>
storage_element =  shape_type(name='action', shape=(), type=<class 'numpy.int32'>)
array_shape =  [100000]
storage_element.name =  action
storage_element.type =  <class 'numpy.int32'>
storage_element =  shape_type(name='reward', shape=(), type=<class 'numpy.float32'>)
array_shape =  [100000]
storage_element.name =  reward
storage_element.type =  <class 'numpy.float32'>
storage_element =  shape_type(name='terminal', shape=(), type=<class 'numpy.uint8'>)
array_shape =  [100000]
storage_element.name =  terminal
storage_element.type =  <class 'numpy.uint8'>
-----------tree_depth = 17 ------------
self._total_priority() =  0.0
self.nodes =  [array([0.]), array([0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.])]
self.max_recorded_priority =  1.0
transition_tensors->
Tensor("sample_replay/sample_replay/StagingArea_get:0", shape=(32, 84, 84, 12), dtype=uint8, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:1", shape=(32,), dtype=int32, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:2", shape=(32,), dtype=float32, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:3", shape=(32, 84, 84, 12), dtype=uint8, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:4", shape=(32,), dtype=uint8, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:5", shape=(32,), dtype=int32, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:6", shape=(?,), dtype=float32, device=/device:CPU:0)
transition_type->
shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>)
shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>)
shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>)
shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>)
shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>)
shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>)
shape_type(name='sampling_probabilities', shape=(None,), type=<class 'numpy.float32'>)
self.transition ->  OrderedDict([('state', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:0' shape=(32, 84, 84, 12) dtype=uint8>), ('action', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:1' shape=(32,) dtype=int32>), ('reward', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:2' shape=(32,) dtype=float32>), ('next_state', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:3' shape=(32, 84, 84, 12) dtype=uint8>), ('terminal', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:4' shape=(32,) dtype=uint8>), ('indices', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:5' shape=(32,) dtype=int32>), ('sampling_probabilities', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:6' shape=(?,) dtype=float32>)])
in DQN _build_networks
 self.online_convnet(self.state_ph)
 --------in RainbowRGBAgent network_template---------
!!!!!!!1 tf.float32 , net ->  Tensor("Online/Cast:0", shape=(1, 84, 84, 12), dtype=float32, device=/device:GPU:0)
 div 255 , net ->  Tensor("Online/div:0", shape=(1, 84, 84, 12), dtype=float32, device=/device:GPU:0)
 conv2d 32, [8,8], stride=4 , net ->  Tensor("Online/Conv/Relu:0", shape=(1, 21, 21, 32), dtype=float32, device=/device:GPU:0)
 conv2d 64, [4, 4], stride=2 , net ->  Tensor("Online/Conv_1/Relu:0", shape=(1, 11, 11, 64), dtype=float32, device=/device:GPU:0)
 conv2d 64, [3, 3], stride=1 , net ->  Tensor("Online/Conv_2/Relu:0", shape=(1, 11, 11, 64), dtype=float32, device=/device:GPU:0)
 flatten , net ->  Tensor("Online/Flatten/flatten/Reshape:0", shape=(1, 7744), dtype=float32, device=/device:GPU:0)
 512 , net ->  Tensor("Online/fully_connected/Relu:0", shape=(1, 512), dtype=float32, device=/device:GPU:0)
 fully_connected , net ->  Tensor("Online/fully_connected_1/BiasAdd:0", shape=(1, 255), dtype=float32, device=/device:GPU:0)
---before self.online_convnet(self._replay.states), self._replay.states =  Tensor("sample_replay/sample_replay/StagingArea_get:0", shape=(32, 84, 84, 12), dtype=uint8, device=/device:CPU:0)
 --------in RainbowRGBAgent network_template---------
!!!!!!!1 tf.float32 , net ->  Tensor("Online_1/Cast:0", shape=(32, 84, 84, 12), dtype=float32, device=/device:GPU:0)
 div 255 , net ->  Tensor("Online_1/div:0", shape=(32, 84, 84, 12), dtype=float32, device=/device:GPU:0)
 conv2d 32, [8,8], stride=4 , net ->  Tensor("Online_1/Conv/Relu:0", shape=(32, 21, 21, 32), dtype=float32, device=/device:GPU:0)
 conv2d 64, [4, 4], stride=2 , net ->  Tensor("Online_1/Conv_1/Relu:0", shape=(32, 11, 11, 64), dtype=float32, device=/device:GPU:0)
 conv2d 64, [3, 3], stride=1 , net ->  Tensor("Online_1/Conv_2/Relu:0", shape=(32, 11, 11, 64), dtype=float32, device=/device:GPU:0)
 flatten , net ->  Tensor("Online_1/Flatten/flatten/Reshape:0", shape=(32, 7744), dtype=float32, device=/device:GPU:0)
 512 , net ->  Tensor("Online_1/fully_connected/Relu:0", shape=(32, 512), dtype=float32, device=/device:GPU:0)
 fully_connected , net ->  Tensor("Online_1/fully_connected_1/BiasAdd:0", shape=(32, 255), dtype=float32, device=/device:GPU:0)
---before self.target_convnet(self._replay.next_states)), self._replay.next_states =  Tensor("sample_replay/sample_replay/StagingArea_get:3", shape=(32, 84, 84, 12), dtype=uint8, device=/device:CPU:0)
 --------in RainbowRGBAgent network_template---------
!!!!!!!1 tf.float32 , net ->  Tensor("Target/Cast:0", shape=(32, 84, 84, 12), dtype=float32, device=/device:GPU:0)
 div 255 , net ->  Tensor("Target/div:0", shape=(32, 84, 84, 12), dtype=float32, device=/device:GPU:0)
 conv2d 32, [8,8], stride=4 , net ->  Tensor("Target/Conv/Relu:0", shape=(32, 21, 21, 32), dtype=float32, device=/device:GPU:0)
 conv2d 64, [4, 4], stride=2 , net ->  Tensor("Target/Conv_1/Relu:0", shape=(32, 11, 11, 64), dtype=float32, device=/device:GPU:0)
 conv2d 64, [3, 3], stride=1 , net ->  Tensor("Target/Conv_2/Relu:0", shape=(32, 11, 11, 64), dtype=float32, device=/device:GPU:0)
 flatten , net ->  Tensor("Target/Flatten/flatten/Reshape:0", shape=(32, 7744), dtype=float32, device=/device:GPU:0)
 512 , net ->  Tensor("Target/fully_connected/Relu:0", shape=(32, 512), dtype=float32, device=/device:GPU:0)
 fully_connected , net ->  Tensor("Target/fully_connected_1/BiasAdd:0", shape=(32, 255), dtype=float32, device=/device:GPU:0)
self.state_ph=  Tensor("state_ph:0", shape=(1, 84, 84, 12), dtype=uint8, device=/device:GPU:0)
Creating window glfw
Found 1 GPUs for rendering. Using device 0.
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  0 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  1 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  2 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  3 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  4 , priority =  1.0
Steps executed: 2 Episode length: 2 Return: -1.001rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  5 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  6 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  7 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  8 , priority =  1.0
Steps executed: 3 Episode length: 1 Return: -1.0rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  9 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  10 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  11 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  12 , priority =  1.0
Steps executed: 4 Episode length: 1 Return: -1.0rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  13 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  14 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  15 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  16 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  17 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  18 , priority =  1.0
Steps executed: 7 Episode length: 3 Return: -1.002rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  19 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  20 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  21 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  22 , priority =  1.0
Steps executed: 8 Episode length: 1 Return: -1.0rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  23 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  24 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  25 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  26 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  27 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  28 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  29 , priority =  1.0
Steps executed: 12 Episode length: 4 Return: -1.003rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  30 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  31 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  32 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  33 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  34 , priority =  1.0
Steps executed: 14 Episode length: 2 Return: -1.001rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  35 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  36 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  37 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  38 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  39 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  40 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  41 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  42 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  43 , priority =  1.0
Steps executed: 20 Episode length: 6 Return: -1.005rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  44 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  45 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  46 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  47 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  48 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  49 , priority =  1.0
Steps executed: 23 Episode length: 3 Return: -1.002rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  50 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  51 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  52 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  53 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  54 , priority =  1.0
Steps executed: 25 Episode length: 2 Return: -0.9996775465965938rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  55 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  56 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  57 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  58 , priority =  1.0
Steps executed: 26 Episode length: 1 Return: -1.0rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  59 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  60 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  61 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  62 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  63 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  64 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  65 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  66 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  67 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  68 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  69 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  70 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  71 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  72 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  73 , priority =  1.0
Steps executed: 38 Episode length: 12 Return: -1.011rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  74 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  75 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  76 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  77 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  78 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  79 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  80 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  81 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  82 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  83 , priority =  1.0
Steps executed: 45 Episode length: 7 Return: -1.006rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  84 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  85 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  86 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  87 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  88 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  89 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  90 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  91 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  92 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  93 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  94 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  95 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  96 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  97 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  98 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  99 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  100 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  101 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  102 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  103 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  104 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  105 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  106 , priority =  1.0
Steps executed: 65 Episode length: 20 Return: -1.019rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  107 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  108 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  109 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  110 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  111 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  112 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  113 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  114 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  115 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  116 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  117 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  118 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  119 , priority =  1.0
Steps executed: 75 Episode length: 10 Return: -1.009rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  120 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  121 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  122 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  123 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  124 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  125 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  126 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  127 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  128 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  129 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  130 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  131 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  132 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  133 , priority =  1.0
Steps executed: 86 Episode length: 11 Return: -1.01rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  134 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  135 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  136 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  137 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  138 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  139 , priority =  1.0
Steps executed: 89 Episode length: 3 Return: -1.002rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  140 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  141 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  142 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  143 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  144 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  145 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  146 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  147 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  148 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  149 , priority =  1.0
Steps executed: 96 Episode length: 7 Return: -1.006rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  150 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  151 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  152 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  153 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  154 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  155 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  156 , priority =  1.0
Steps executed: 100 Episode length: 4 Return: -1.003rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  157 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  158 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  159 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  160 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  161 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  162 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  163 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  164 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  165 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  166 , priority =  1.0
rainbow agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1.0
_add() self.cursor() =  167 , priority =  1.0
Steps executed: 108 Episode length: 8 Return: -1.007