in fetch_cam __init__
Choosing the latest nvidia driver: /usr/lib/nvidia-396, among ['/usr/lib/nvidia-375', '/usr/lib/nvidia-396']
Choosing the latest nvidia driver: /usr/lib/nvidia-396, among ['/usr/lib/nvidia-375', '/usr/lib/nvidia-396']
in continuous trani and eval
--------in RainbowRGBAgent------
in RGBGripper rainbow   _build_replay_buffer
self._observation_shape=(84, 84, 3), len(self._observation_shape)=3
storage_element =  shape_type(name='observation', shape=(84, 84, 3), type=<class 'numpy.uint8'>)
array_shape =  [100000, 84, 84, 3]
storage_element.name =  observation
storage_element.type =  <class 'numpy.uint8'>
storage_element =  shape_type(name='action', shape=(), type=<class 'numpy.int32'>)
array_shape =  [100000]
storage_element.name =  action
storage_element.type =  <class 'numpy.int32'>
storage_element =  shape_type(name='reward', shape=(), type=<class 'numpy.float32'>)
array_shape =  [100000]
storage_element.name =  reward
storage_element.type =  <class 'numpy.float32'>
storage_element =  shape_type(name='terminal', shape=(), type=<class 'numpy.uint8'>)
array_shape =  [100000]
storage_element.name =  terminal
storage_element.type =  <class 'numpy.uint8'>
storage_element =  shape_type(name='gripper', shape=(), type=<class 'numpy.uint8'>)
array_shape =  [100000]
storage_element.name =  gripper
storage_element.type =  <class 'numpy.uint8'>
-----------tree_depth = 17 ------------
self._total_priority() =  0.0
self.nodes =  [array([0.]), array([0., 0.]), array([0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.])]
self.max_recorded_priority =  1.0
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_tensors->
Tensor("sample_replay/sample_replay/StagingArea_get:0", shape=(32, 84, 84, 12), dtype=uint8, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:1", shape=(32,), dtype=int32, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:2", shape=(32,), dtype=float32, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:3", shape=(32, 84, 84, 12), dtype=uint8, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:4", shape=(32,), dtype=uint8, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:5", shape=(32,), dtype=int32, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:6", shape=(32,), dtype=uint8, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:7", shape=(32,), dtype=uint8, device=/device:CPU:0)
Tensor("sample_replay/sample_replay/StagingArea_get:8", shape=(?,), dtype=float32, device=/device:CPU:0)
transition_type->
shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>)
shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>)
shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>)
shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>)
shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>)
shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>)
shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>)
shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)
shape_type(name='sampling_probabilities', shape=(None,), type=<class 'numpy.float32'>)
self.transition ->  OrderedDict([('state', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:0' shape=(32, 84, 84, 12) dtype=uint8>), ('action', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:1' shape=(32,) dtype=int32>), ('reward', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:2' shape=(32,) dtype=float32>), ('next_state', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:3' shape=(32, 84, 84, 12) dtype=uint8>), ('terminal', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:4' shape=(32,) dtype=uint8>), ('indices', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:5' shape=(32,) dtype=int32>), ('gripper', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:6' shape=(32,) dtype=uint8>), ('next_gripper', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:7' shape=(32,) dtype=uint8>), ('sampling_probabilities', <tf.Tensor 'sample_replay/sample_replay/StagingArea_get:8' shape=(?,) dtype=float32>)])
in rainbow_rgb_gripper_ _build_networks
 --------in RainbowRGBAgent network_template---------
 input , state =  Tensor("state_ph:0", shape=(1, 84, 84, 12), dtype=uint8, device=/device:GPU:0) , gripper =  Tensor("gripper_ph:0", shape=(1, 1), dtype=uint8, device=/device:GPU:0)
before gripper net  Tensor("Online/fully_connected/Relu:0", shape=(1, 512), dtype=float32, device=/device:GPU:0)
gripper  Tensor("Online/Cast_1:0", shape=(1, 1), dtype=float32, device=/device:GPU:0)
after gripper net  Tensor("Online/concat:0", shape=(1, 513), dtype=float32, device=/device:GPU:0)
 fully_connected , net ->  Tensor("Online/fully_connected_1/BiasAdd:0", shape=(1, 306), dtype=float32, device=/device:GPU:0)
---before self.online_convnet(self._replay.states), self._replay.states =  Tensor("sample_replay/sample_replay/StagingArea_get:0", shape=(32, 84, 84, 12), dtype=uint8, device=/device:CPU:0) , self._replay.gripper =  Tensor("sample_replay/sample_replay/StagingArea_get:6", shape=(32,), dtype=uint8, device=/device:CPU:0)
 --------in RainbowRGBAgent network_template---------
 input , state =  Tensor("sample_replay/sample_replay/StagingArea_get:0", shape=(32, 84, 84, 12), dtype=uint8, device=/device:CPU:0) , gripper =  Tensor("Online_1/ExpandDims:0", shape=(32, 1), dtype=uint8, device=/device:GPU:0)
before gripper net  Tensor("Online_1/fully_connected/Relu:0", shape=(32, 512), dtype=float32, device=/device:GPU:0)
gripper  Tensor("Online_1/Cast_1:0", shape=(32, 1), dtype=float32, device=/device:GPU:0)
after gripper net  Tensor("Online_1/concat:0", shape=(32, 513), dtype=float32, device=/device:GPU:0)
 fully_connected , net ->  Tensor("Online_1/fully_connected_1/BiasAdd:0", shape=(32, 306), dtype=float32, device=/device:GPU:0)
---before self.target_convnet(self._replay.next_states)), self._replay.next_states =  Tensor("sample_replay/sample_replay/StagingArea_get:3", shape=(32, 84, 84, 12), dtype=uint8, device=/device:CPU:0) ,self._replay.next_gripper= Tensor("sample_replay/sample_replay/StagingArea_get:7", shape=(32,), dtype=uint8, device=/device:CPU:0)
 --------in RainbowRGBAgent network_template---------
 input , state =  Tensor("sample_replay/sample_replay/StagingArea_get:3", shape=(32, 84, 84, 12), dtype=uint8, device=/device:CPU:0) , gripper =  Tensor("Target/ExpandDims:0", shape=(32, 1), dtype=uint8, device=/device:GPU:0)
before gripper net  Tensor("Target/fully_connected/Relu:0", shape=(32, 512), dtype=float32, device=/device:GPU:0)
gripper  Tensor("Target/Cast_1:0", shape=(32, 1), dtype=float32, device=/device:GPU:0)
after gripper net  Tensor("Target/concat:0", shape=(32, 513), dtype=float32, device=/device:GPU:0)
 fully_connected , net ->  Tensor("Target/fully_connected_1/BiasAdd:0", shape=(32, 306), dtype=float32, device=/device:GPU:0)
self.state_ph=  Tensor("state_ph:0", shape=(1, 84, 84, 12), dtype=uint8, device=/device:GPU:0)
Creating window glfw
Found 1 GPUs for rendering. Using device 0.
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  0 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  1 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  2 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  3 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  4 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  5 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  6 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  7 , priority =  0
Steps executed: 5 Episode length: 5 Return: -1.004rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  8 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  9 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  10 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  11 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  12 , priority =  0
Steps executed: 7 Episode length: 2 Return: -1.001rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  13 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  14 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  15 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  16 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  17 , priority =  0
Steps executed: 9 Episode length: 2 Return: -1.001rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  18 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  19 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  20 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  21 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  22 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  23 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  24 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  25 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  26 , priority =  0
Steps executed: 15 Episode length: 6 Return: -1.005rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  27 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  28 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  29 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  30 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.0
rainbow rgb gripper agent priority after =  1.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1
_add() self.cursor() =  31 , priority =  1
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1
_add() self.cursor() =  32 , priority =  1
rainbow rgb gripper agent priority =  1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  33 , priority =  0
Steps executed: 19 Episode length: 4 Return: -1.003rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  34 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  35 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  36 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  37 , priority =  0
Steps executed: 20 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  38 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  39 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  40 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  41 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  42 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  43 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  44 , priority =  0
Steps executed: 24 Episode length: 4 Return: -1.003rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  45 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  46 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  47 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  48 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  49 , priority =  0
Steps executed: 26 Episode length: 2 Return: -1.001rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  50 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  51 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  52 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  53 , priority =  0
rainbow rgb gripper agent priority =  1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  54 , priority =  0
Steps executed: 28 Episode length: 2 Return: -1.001rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  55 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  56 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  57 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  58 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1
_add() self.cursor() =  59 , priority =  1
rainbow rgb gripper agent priority =  1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  60 , priority =  0
Steps executed: 31 Episode length: 3 Return: -1.0008011629087394rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  61 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  62 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  63 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  64 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1
_add() self.cursor() =  65 , priority =  1
rainbow rgb gripper agent priority =  1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  66 , priority =  0
Steps executed: 34 Episode length: 3 Return: -1.002rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  67 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  68 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  69 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  70 , priority =  0
Steps executed: 35 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  71 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  72 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  73 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  74 , priority =  0
Steps executed: 36 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  75 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  76 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  77 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  78 , priority =  0
Steps executed: 37 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  79 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  80 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  81 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  82 , priority =  0
Steps executed: 38 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  83 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  84 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  85 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  86 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  87 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  88 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  89 , priority =  0
Steps executed: 42 Episode length: 4 Return: -1.003rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  90 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  91 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  92 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  93 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  94 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  95 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  96 , priority =  0
Steps executed: 46 Episode length: 4 Return: -1.003rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  97 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  98 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  99 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  100 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  101 , priority =  0
---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  4.0
indices -> [31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 59, 59, 59, 59, 59, 59, 59, 59, 65, 65, 65, 65, 65, 65, 65, 65]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 59 59 59 59 59 59 59 59
 65 65 65 65 65 65 65 65] , priorities =  [1.983785  1.983785  1.983785  1.983785  1.983785  1.983785  1.983785
 1.983785  1.9654818 1.9654818 1.9654818 1.9654818 1.9654818 1.9654818
 1.9654818 1.9654818 1.983348  1.983348  1.983348  1.983348  1.983348
 1.983348  1.983348  1.983348  1.9874517 1.9874517 1.9874517 1.9874517
 1.9874517 1.9874517 1.9874517 1.9874517]
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  102 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  103 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  104 , priority =  0
Steps executed: 51 Episode length: 5 Return: -1.004rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  105 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  106 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  107 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  108 , priority =  0
Steps executed: 52 Episode length: 1 Return: -1.0---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  7.920066475868225
indices -> [31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 59, 59, 59, 59, 59, 59, 59, 59, 65, 65, 65, 65, 65, 65, 65, 65]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 59 59 59 59 59 59 59 59
 65 65 65 65 65 65 65 65] , priorities =  [1.9757147 1.9757147 1.9757147 1.9757147 1.9757147 1.9757147 1.9757147
 1.9757147 1.9566926 1.9566926 1.9566926 1.9566926 1.9566926 1.9566926
 1.9566926 1.9566926 1.9759077 1.9759077 1.9759077 1.9759077 1.9759077
 1.9759077 1.9759077 1.9759077 1.9831057 1.9831057 1.9831057 1.9831057
 1.9831057 1.9831057 1.9831057 1.9831057]
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  109 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  110 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  111 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  112 , priority =  0
Steps executed: 53 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  113 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  114 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  115 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  116 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  117 , priority =  0
Steps executed: 55 Episode length: 2 Return: -1.001rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  118 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  119 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  120 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  121 , priority =  0
---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  7.891420602798462
indices -> [31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 59, 59, 59, 59, 59, 59, 59, 59, 65, 65, 65, 65, 65, 65, 65, 65]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 59 59 59 59 59 59 59 59
 65 65 65 65 65 65 65 65] , priorities =  [1.9658569 1.9658569 1.9658569 1.9658569 1.9658569 1.9658569 1.9658569
 1.9658569 1.9463253 1.9463253 1.9463253 1.9463253 1.9463253 1.9463253
 1.9463253 1.9463253 1.9669248 1.9669248 1.9669248 1.9669248 1.9669248
 1.9669248 1.9669248 1.9669248 1.9783477 1.9783477 1.9783477 1.9783477
 1.9783477 1.9783477 1.9783477 1.9783477]
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1
_add() self.cursor() =  122 , priority =  1
rainbow rgb gripper agent priority =  1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  123 , priority =  0
Steps executed: 58 Episode length: 3 Return: -1.002rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  124 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  125 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  126 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  127 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1
_add() self.cursor() =  128 , priority =  1
---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  9.857454657554626
indices -> [31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 59, 59, 59, 59, 59, 59, 65, 65, 65, 65, 65, 65, 122, 122, 122, 128, 128, 128, 128]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 59 59 59 59 59 59 59 59
 65 65 65 65 65 65 65 65] , priorities =  [1.9554825 1.9554825 1.9554825 1.9554825 1.9554825 1.9554825 1.9554825
 1.9554825 1.9344817 1.9344817 1.9344817 1.9344817 1.9344817 1.9344817
 1.9344817 1.9344817 1.956792  1.956792  1.956792  1.956792  1.956792
 1.956792  1.956792  1.956792  1.9733851 1.9733851 1.9733851 1.9733851
 1.9733851 1.9733851 1.9733851 1.9733851]
rainbow rgb gripper agent priority =  1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  129 , priority =  0
Steps executed: 61 Episode length: 3 Return: -1.002rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  130 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  131 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  132 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  133 , priority =  0
Steps executed: 62 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  134 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  135 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  136 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  137 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  138 , priority =  0
Steps executed: 64 Episode length: 2 Return: -1.001---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  9.820141315460205
indices -> [31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 59, 59, 59, 59, 59, 59, 65, 65, 65, 65, 65, 65, 65, 122, 122, 122, 128, 128, 128]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [ 31  31  31  31  31  31  32  32  32  32  32  32  32  59  59  59  59  59
  59  65  65  65  65  65  65 122 122 122  65  65  59  31] , priorities =  [1.9438386 1.9438386 1.9438386 1.9438386 1.9438386 1.9438386 1.9219403
 1.9219403 1.9219403 1.9219403 1.9219403 1.9219403 1.9219403 1.9455558
 1.9455558 1.9455558 1.9455558 1.9455558 1.9455558 1.9681891 1.9681891
 1.9681891 1.9681891 1.9681891 1.9681891 1.9698993 1.9698993 1.9698993
 1.9681891 1.9681891 1.9455558 1.9438386]
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  139 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  140 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  141 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  142 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  143 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  144 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  145 , priority =  0
Steps executed: 68 Episode length: 4 Return: -1.003---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  10.749423146247864
indices -> [31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 59, 59, 59, 59, 59, 59, 59, 65, 65, 65, 65, 65, 122, 122, 122, 122, 122, 122, 128, 128, 128]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [ 31  31  31  31  31  31  31  32  32  32  32  32  32  59  59  59  59  59
  59  65  65  65  65  65  65  65 122 122 122 128 128 128] , priorities =  [1.9320354 1.9320354 1.9320354 1.9320354 1.9320354 1.9320354 1.9320354
 1.9093527 1.9093527 1.9093527 1.9093527 1.9093527 1.9093527 1.9338212
 1.9338212 1.9338212 1.9338212 1.9338212 1.9338212 1.961903  1.961903
 1.961903  1.961903  1.961903  1.961903  1.961903  1.9636174 1.9636174
 1.9636174 1.9349083 1.9349083 1.9349083]
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  146 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  147 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  148 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  149 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  150 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  151 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  152 , priority =  0
Steps executed: 72 Episode length: 4 Return: -1.003---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  11.635637998580933
indices -> [31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 59, 59, 59, 59, 59, 65, 65, 65, 65, 65, 122, 122, 122, 122, 122, 122, 128, 128, 128, 128, 128]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [ 31  31  31  31  31  31  32  32  32  32  32  59  59  59  59  59  59  59
  65  65  65  65  65 122 122 122 122 122 122 128 128 128] , priorities =  [1.9187865 1.9187865 1.9187865 1.9187865 1.9187865 1.9187865 1.8966807
 1.8966807 1.8966807 1.8966807 1.8966807 1.9209297 1.9209297 1.9209297
 1.9209297 1.9209297 1.9209297 1.9209297 1.95484   1.95484   1.95484
 1.95484   1.95484   1.956492  1.956492  1.956492  1.956492  1.956492
 1.956492  1.9219302 1.9219302 1.9219302]
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  153 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  154 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  155 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  156 , priority =  0
Steps executed: 73 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  157 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  158 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  159 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  160 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  161 , priority =  0
Steps executed: 75 Episode length: 2 Return: -1.001rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  162 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  163 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  164 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  165 , priority =  0
---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  11.569658994674683
indices -> [31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 59, 59, 59, 59, 59, 65, 65, 65, 65, 65, 122, 122, 122, 122, 122, 128, 128, 128, 128, 128, 128]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [ 31  31  31  31  31  32  32  32  32  32  32  59  59  59  59  59  65  65
  65  65  65 122 122 122 122 122 122 128 128 128 128 128] , priorities =  [1.9041256 1.9041256 1.9041256 1.9041256 1.9041256 1.8835536 1.8835536
 1.8835536 1.8835536 1.8835536 1.8835536 1.906617  1.906617  1.906617
 1.906617  1.906617  1.9466631 1.9466631 1.9466631 1.9466631 1.9466631
 1.9485747 1.9485747 1.9485747 1.9485747 1.9485747 1.9485747 1.9074522
 1.9074522 1.9074522 1.9074522 1.9074522]
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  1
_add() self.cursor() =  166 , priority =  1
rainbow rgb gripper agent priority =  1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  167 , priority =  0
Steps executed: 78 Episode length: 3 Return: -1.002rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  168 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  169 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  170 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  171 , priority =  0
Steps executed: 79 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  172 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  173 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  174 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  175 , priority =  0
---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  12.496986269950867
indices -> [31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 59, 59, 59, 59, 59, 65, 65, 65, 65, 65, 122, 122, 122, 122, 128, 128, 128, 128, 128, 128, 166, 166]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [ 31  31  31  31  31  32  32  32  32  32  32  59  59  59  59  59  65  65
  65  65  65 122 122 122 122 122 128 128 128 128 128 128] , priorities =  [1.8871078 1.8871078 1.8871078 1.8871078 1.8871078 1.8686533 1.8686533
 1.8686533 1.8686533 1.8686533 1.8686533 1.8899683 1.8899683 1.8899683
 1.8899683 1.8899683 1.9371704 1.9371704 1.9371704 1.9371704 1.9371704
 1.9394897 1.9394897 1.9394897 1.9394897 1.9394897 1.8905494 1.8905494
 1.8905494 1.8905494 1.8905494 1.8905494]
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  176 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  177 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  178 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  179 , priority =  0
Steps executed: 84 Episode length: 5 Return: -1.004---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  12.412938952445984
indices -> [31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 59, 59, 59, 59, 59, 65, 65, 65, 65, 65, 122, 122, 122, 122, 122, 128, 128, 128, 128, 128, 166, 166]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [ 31  31  31  31  31  32  32  32  32  32  59  59  59  59  59  65  65  65
  65  65 122 122 122 122 128 128 128 128 128 128 166 166] , priorities =  [1.8670266 1.8670266 1.8670266 1.8670266 1.8670266 1.8516972 1.8516972
 1.8516972 1.8516972 1.8516972 1.8704785 1.8704785 1.8704785 1.8704785
 1.8704785 1.9263494 1.9263494 1.9263494 1.9263494 1.9263494 1.9289794
 1.9289794 1.9289794 1.9289794 1.8704585 1.8704585 1.8704585 1.8704585
 1.8704585 1.8704585 1.8697903 1.8697903]
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  180 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  181 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  182 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  183 , priority =  0
Steps executed: 85 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  184 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  185 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  186 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  187 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  188 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  189 , priority =  0
Steps executed: 88 Episode length: 3 Return: -1.002---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  13.18477988243103
indices -> [31, 31, 31, 31, 32, 32, 32, 32, 32, 59, 59, 59, 59, 65, 65, 65, 65, 65, 122, 122, 122, 122, 122, 128, 128, 128, 128, 166, 166, 166, 166, 166]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [ 31  31  31  31  31  32  32  32  32  32  59  59  59  59  59  65  65  65
  65  65 122 122 122 122 122 128 128 128 128 128 166 166] , priorities =  [1.8441519 1.8441519 1.8441519 1.8441519 1.8441519 1.8331891 1.8331891
 1.8331891 1.8331891 1.8331891 1.8482522 1.8482522 1.8482522 1.8482522
 1.8482522 1.9145553 1.9145553 1.9145553 1.9145553 1.9145553 1.9176348
 1.9176348 1.9176348 1.9176348 1.9176348 1.8473103 1.8473103 1.8473103
 1.8473103 1.8473103 1.8470612 1.8470612]
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  190 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  191 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  192 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  193 , priority =  0
Steps executed: 89 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  194 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  195 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  196 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  197 , priority =  0
rainbow rgb gripper agent priority =  1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  198 , priority =  0
Steps executed: 91 Episode length: 2 Return: -1.001rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  199 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  200 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  201 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  202 , priority =  0
---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  13.052154779434204
indices -> [31, 31, 31, 31, 31, 32, 32, 32, 32, 59, 59, 59, 59, 59, 65, 65, 65, 65, 65, 122, 122, 122, 122, 128, 128, 128, 128, 166, 166, 166, 166, 166]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [ 31  31  31  31  32  32  32  32  32  59  59  59  59  65  65  65  65  65
 122 122 122 122 122 128 128 128 128 166 166 166 166 166] , priorities =  [1.8181834 1.8181834 1.8181834 1.8181834 1.8128961 1.8128961 1.8128961
 1.8128961 1.8128961 1.8228475 1.8228475 1.8228475 1.8228475 1.9013457
 1.9013457 1.9013457 1.9013457 1.9013457 1.9048872 1.9048872 1.9048872
 1.9048872 1.9048872 1.8211032 1.8211032 1.8211032 1.8211032 1.8214238
 1.8214238 1.8214238 1.8214238 1.8214238]
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  203 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  204 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  205 , priority =  0
Steps executed: 95 Episode length: 4 Return: -1.003rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  206 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  207 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  208 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  209 , priority =  0
Steps executed: 96 Episode length: 1 Return: -1.0---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  12.902686953544617
indices -> [31, 31, 31, 31, 31, 32, 32, 32, 32, 59, 59, 59, 59, 65, 65, 65, 65, 65, 122, 122, 122, 122, 122, 128, 128, 128, 128, 128, 166, 166, 166, 166]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [ 31  31  31  31  31  32  32  32  32  59  59  59  59  59  65  65  65  65
  65 122 122 122 122 128 128 128 128 166 166 166 166 166] , priorities =  [1.787631  1.787631  1.787631  1.787631  1.787631  1.7900883 1.7900883
 1.7900883 1.7900883 1.793597  1.793597  1.793597  1.793597  1.793597
 1.8863599 1.8863599 1.8863599 1.8863599 1.8863599 1.8903457 1.8903457
 1.8903457 1.8903457 1.79077   1.79077   1.79077   1.79077   1.7914299
 1.7914299 1.7914299 1.7914299 1.7914299]
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  210 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  211 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  212 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  213 , priority =  0
Steps executed: 97 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  214 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  215 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  216 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  217 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  218 , priority =  0
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  219 , priority =  0
Steps executed: 100 Episode length: 3 Return: -1.002---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  12.73022186756134
indices -> [31, 31, 31, 31, 31, 32, 32, 32, 32, 59, 59, 59, 59, 65, 65, 65, 65, 65, 122, 122, 122, 122, 122, 128, 128, 128, 128, 128, 166, 166, 166, 166]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [ 31  31  31  31  31  32  32  32  32  59  59  59  59  65  65  65  65  65
 122 122 122 122 122 128 128 128 128 128 166 166 166 166] , priorities =  [1.7521361 1.7521361 1.7521361 1.7521361 1.7521361 1.764682  1.764682
 1.764682  1.764682  1.7593253 1.7593253 1.7593253 1.7593253 1.8698025
 1.8698025 1.8698025 1.8698025 1.8698025 1.8742423 1.8742423 1.8742423
 1.8742423 1.8742423 1.7552439 1.7552439 1.7552439 1.7552439 1.7552439
 1.7559562 1.7559562 1.7559562 1.7559562]
rainbow rgb gripper agent priority =  0
rainbow rgb gripper agent priority after =  0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  220 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  221 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  222 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  223 , priority =  0
Steps executed: 101 Episode length: 1 Return: -1.0rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  224 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  225 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  226 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  227 , priority =  0
rainbow rgb gripper agent priority =  1
rainbow rgb gripper agent priority after =  1
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  228 , priority =  0
Steps executed: 103 Episode length: 2 Return: -1.001rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  229 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  230 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0.0
_add() self.cursor() =  231 , priority =  0.0
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  232 , priority =  0
---in sample_index_batch
self.sum_tree =  <dopamine.replay_memory.sum_tree.SumTree object at 0x7f2a3734dd30>
self._total_priority() =  12.531388282775879
indices -> [31, 31, 31, 31, 32, 32, 32, 32, 32, 59, 59, 59, 59, 65, 65, 65, 65, 65, 122, 122, 122, 122, 122, 128, 128, 128, 128, 128, 166, 166, 166, 166]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  31
trajectory_indices =  [31, 32, 33] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  32
trajectory_indices =  [32, 33, 34] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  59
trajectory_indices =  [59, 60, 61] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  65
trajectory_indices =  [65, 66, 67] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  122
trajectory_indices =  [122, 123, 124] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  128
trajectory_indices =  [128, 129, 130] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
state_index =  166
trajectory_indices =  [166, 167, 168] , self._update_horizon =  3
transition_elements ->  [shape_type(name='state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='action', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='reward', shape=(32,), type=<class 'numpy.float32'>), shape_type(name='next_state', shape=(32, 84, 84, 12), type=<class 'numpy.uint8'>), shape_type(name='terminal', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='indices', shape=(32,), type=<class 'numpy.int32'>), shape_type(name='gripper', shape=(32,), type=<class 'numpy.uint8'>), shape_type(name='next_gripper', shape=(32,), type=<class 'numpy.uint8'>)]
---in set_priority =  [ 31  31  31  31  31  32  32  32  32  59  59  59  59  65  65  65  65  65
 122 122 122 122 122 128 128 128 128 128 166 166 166 166] , priorities =  [1.7113411 1.7113411 1.7113411 1.7113411 1.7113411 1.7369888 1.7369888
 1.7369888 1.7369888 1.7198591 1.7198591 1.7198591 1.7198591 1.8506582
 1.8506582 1.8506582 1.8506582 1.8506582 1.8555324 1.8555324 1.8555324
 1.8555324 1.8555324 1.7144604 1.7144604 1.7144604 1.7144604 1.7144604
 1.7152556 1.7152556 1.7152556 1.7152556]
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  233 , priority =  0
rainbow rgb gripper agent priority =  None
 self._replay_scheme= prioritized , self._replay.memory.sum_tree.max_recorded_priority= 1.9874517
rainbow rgb gripper agent priority after =  1.9874517
element =  shape_type(name='priority', shape=(), type=<class 'numpy.float32'>) , args[i] =  0
_add() self.cursor() =  234 , priority =  0
